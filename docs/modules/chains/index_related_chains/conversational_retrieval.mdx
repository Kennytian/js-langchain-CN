---
hide_table_of_contents: true
sidebar_position: 3
---

import CodeBlock from "@theme/CodeBlock";

import ConvoRetrievalQAExample from "@examples/chains/conversational_qa.ts";


# 对话式检索问答

`ConversationalRetrievalQA` 链基于 `RetrievalQAChain` 构建，提供了聊天历史记录组件。

它首先将聊天历史记录（显式传递或从提供的记忆中检索）与问题组合为一个独立的问题，然后从检索器中查找相关文档，最后将这些文档和问题传递到问答链中返回响应。

要创建一个 `ConversationalRetrievalQA`，你需要一个检索器。在下面的示例中，我们将从 向量存储 创建一个检索器，该存储可以从嵌入中创建。

import Example from "@examples/chains/conversational_qa.ts";


<CodeBlock language="typescript">{ConvoRetrievalQAExample}</CodeBlock>


在上面的代码片段中，`ConversationalRetrievalQAChain` 类的 `fromLLM` 方法具有以下签名:

```typescript
static fromLLM(

  llm: BaseLanguageModel,

  retriever: BaseRetriever,

  options?: {

    questionGeneratorChainOptions?: {

      llm?: BaseLanguageModel;

      template?: string;

    };

    qaChainOptions?: QAChainParams;

    returnSourceDocuments?: boolean;

  }

): ConversationalRetrievalQAChain

```


以下是选项对象每个属性的说明:

- `questionGeneratorChainOptions`: 一个对象，允许你传递自定义模板和LLM到底层的问题生成链中。
  - If the template is provided, the `ConversationalRetrievalQAChain` will use this template to generate a question from the conversation context instead of using the question provided in the question parameter.

    This can be useful if the original question does not contain enough information to retrieve a suitable answer.

  - Passing in a separate LLM here allows you to use a cheaper/faster model to create the condensed question while using a more powerful model for the final response, and can reduce unnecessary latency.

- `qaChainOptions`: 允许你自定义在最后一步使用的特定QA链的选项。默认值为 [`StuffDocumentsChain`](/docs/modules/chains/index_related_chains/document_qa) ，但你可以通过传递 `type` 参数来自定义使用哪个链。
  **Passing specific options here is completely optional**, but can be useful if you want to customize the way the response is presented to the end user, or if you have too many documents for the default `StuffDocumentsChain`.

  You can see [documentation about the usable fields here](/docs/api/chains/types/QAChainParams).

- `returnSourceDocuments`: 一个布尔值，表示 `ConversationalRetrievalQAChain` 是否应返回用于检索答案的源文档。如果设置为 true，则文档将包含在 `call()` 方法返回的结果中。如果不设置，则默认值为 false。这对于允许用户查看生成答案所使用的来源非常有用。
  - If you are using this option and passing in a memory instance, set `inputKey` and `outputKey` on the memory instance to the same values as the chain input and final conversational chain output. These default to `"question"` and `"text"` respectively, and specify the values that the memory should store.



## 内置存储器

以下是一个使用更快的LLM生成问题和更全面的LLM生成最终答案的自定义示例。它使用内置存储对象，并返回所引用的源文档。# Built-in Memory

import ConvoQABuiltInExample from "@examples/chains/conversational_qa_built_in_memory.ts";


<CodeBlock language="typescript">{ConvoQABuiltInExample}</CodeBlock>


## 流式处理

您还可以使用上述使用两个不同的LLM来仅从链中流式传输最终响应而不是中间独立问题生成步骤的输出的概念。以下是一个示例。# Streaming

import ConvoQAStreamingExample from "@examples/chains/conversational_qa_streaming.ts";


<CodeBlock language="typescript">{ConvoQAStreamingExample}</CodeBlock>


## 外部管理的存储器

如果您希望以特定方式格式化聊天历史记录，则还可以通过省略`memory`选项并直接将`chat_history`字符串传递到`chain.call`方法中来显式传递聊天历史记录。# Externally-Managed Memory


import ConvoQAExternalMemoryExample from "@examples/chains/conversational_qa_external_memory.ts";



<CodeBlock language="typescript">{ConvoQAExternalMemoryExample}</CodeBlock>

