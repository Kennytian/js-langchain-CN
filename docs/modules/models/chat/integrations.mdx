---
sidebar_position: 3
sidebar_label: 集成
---

import CodeBlock from "@theme/CodeBlock";


# 集成: 聊天模型

LangChain提供了许多与不同模型提供者集成的聊天模型实现。它们如下所示:

## `ChatOpenAI`（聊天OpenAI）

import OpenAI from "@examples/models/chat/integration_openai.ts";


<CodeBlock language="typescript">{OpenAI}</CodeBlock>


## Azure `ChatOpenAI`（Azure的聊天OpenAI）

import AzureOpenAI from "@examples/models/chat/integration_azure_openai.ts";


<CodeBlock language="typescript">{AzureOpenAI}</CodeBlock>


## `ChatAnthropic`（聊天Anthropic）

import Anthropic from "@examples/models/chat/integration_anthropic.ts";


<CodeBlock language="typescript">{Anthropic}</CodeBlock>


## `PromptLayerChatOpenAI`（Prompt Layer聊天OpenAI）

可以传入可选的 `returnPromptLayerId` 布尔值来获取像下面这样的 `promptLayerRequestId`。下面是一个获取 PromptLayerChatOpenAI 请求ID 的示例:

```typescript
import { PromptLayerChatOpenAI } from "langchain/chat_models/openai";



const chat = new PromptLayerChatOpenAI({

  returnPromptLayerId: true,

});



const respA = await chat.generate([

  [

    new SystemChatMessage(

      "You are a helpful assistant that translates English to French."

    ),

  ],

]);



console.log(JSON.stringify(respA, null, 3));



/*

  {

    "generations": [

      [

        {

          "text": "Bonjour! Je suis un assistant utile qui peut vous aider à traduire de l'anglais vers le français. Que puis-je faire pour vous aujourd'hui?",

          "message": {

            "type": "ai",

            "data": {

              "content": "Bonjour! Je suis un assistant utile qui peut vous aider à traduire de l'anglais vers le français. Que puis-je faire pour vous aujourd'hui?"

            }

          },

          "generationInfo": {

            "promptLayerRequestId": 2300682

          }

        }

      ]

    ],

    "llmOutput": {

      "tokenUsage": {

        "completionTokens": 35,

        "promptTokens": 19,

        "totalTokens": 54

      }

    }

  }

*/

```


## `Google Vertex AI`（Google 顶点AI）

Vertex AI 实现旨在在 Node.js 中使用，而不是直接从浏览器中使用，因为需要使用服务帐户才能使用。

在运行此代码之前，您应该确保已为相关项目启用了 Vertex AI API，并且已经使用以下方法之一进行了 Google Cloud 身份验证:

- 您已登录帐户（使用 `gcloud auth application-default login`）
Google Cloud using one of these methods:

- 您正在运行使用允许的服务帐户的机器上
- You are logged into an account (using `gcloud auth application-default login`)

- 您已下载允许的服务帐户的凭据
- You are running on a machine using a service account that is permitted

  to the project.

- You have downloaded the credentials for a service account that is permitted

  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment

  variable to the path of this file.


```bash npm2yarn
npm install google-auth-library

```


ChatGoogleVertexAI 类的工作方式与其他基于聊天的 LLM 相同，具有一些例外情况:

1. 第一个传入的 `SystemChatMessage` 被映射到 PaLM 模型期望的 "context" 参数。
1. The first `SystemChatMessage` passed in is mapped to the "context" parameter that the PaLM model expects.

   No other `SystemChatMessages` are allowed.

2. After the first `SystemChatMessage`, there must be an odd number of messages, representing a conversation between a human and the model.

3. 人类信息必须与AI信息交替出现。


import ChatGoogleVertexAI from "@examples/models/chat/integration_googlevertexai.ts";



<CodeBlock language="typescript">{ChatGoogleVertexAI}</CodeBlock>



此外，还有一个可选的“例子”构造参数，可以帮助模型理解什么是适当的响应。
看起来像。


import ChatGoogleVertexAIExamples from "@examples/models/chat/integration_googlevertexai-examples.ts";



<CodeBlock language="typescript">{ChatGoogleVertexAIExamples}</CodeBlock>

